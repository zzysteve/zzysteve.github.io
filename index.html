<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Zongye Zhang</title>

    <meta name="author" content="Zongye Zhang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Zongye Zhang
                </p>
                <p>
                  Currently a third year Ph.D. student at the <a href="https://irip.buaa.edu.cn">Intelligent Recognition and Image Processing (IRIP) Lab</a> from <a href="https://ev.buaa.edu.cn/">Beihang University</a>, advised by <a href="https://shi.buaa.edu.cn/liuqingjie/zh_CN/index/8355/list/index.htm">Prof. Qingjie Liu</a>.
                </p>
                <p>
                  My research interests revolve broadly across computer vision, generative models (diffusion models, vision-language models, etc.), and human-centric tasks.
                </p>
                <p style="text-align:center">
                  <a href="mailto:zhangzongye@buaa.edu.cn">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp; -->
                  <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=7JxjxxwAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp; -->
                  <!-- <a href="https://bsky.app/profile/jonbarron.bsky.social">Bluesky</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/zzysteve/">Github</a>
                </p>
              </td>
              <!-- <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/ZongyeZhang.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/ZongyeZhang.jpg" class="hoverZoomLink"></a>
              </td> -->
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  Most of my work focuses on human-centric understanding and generation. Recently, I am exploring the integration of human-centric tasks with large language models (LLMs) to build more capable and interactive multimodal systems.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="MoMADiff_stop()" onmouseover="MoMADiff_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='momadiff_vid'></div>
          <img src='images/momadiff/index_image.png' width="160">
        </div>
        <script type="text/javascript">
          function MoMADiff_start() {
            document.getElementById('momadiff_vid').style.opacity = "1";
          }

          function MoMADiff_stop() {
            document.getElementById('momadiff_vid').style.opacity = "0";
          }
          MoMADiff_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2505.11013">
          <span class="papertitle">Towards Robust and Controllable Text-to-Motion via Masked Autoregressive Diffusion</span>
        </a>
        <br>
        <a href="https://zzysteve.github.io/">Zongye Zhang</a>,
        Bohan Kong,
        <a href="https://scholar.google.com/citations?user=HsLdRZYAAAAJ">Qingjie Liu</a>,
        <a href="https://scholar.google.com/citations?user=0ez7lA0AAAAJ">Yunhong Wang</a>
        <br>
        <em>ACM Multimedia</em>, 2025
        <br>
        <!-- <a href="https://szymanowiczs.github.io/bolt3d">project page</a> -->
        <a href="https://arxiv.org/pdf/2505.11013">paper</a>
        <p></p>
        <p>
        Exploring generating human motions in continuous representations, which supports arbitrary motion key-frames as input for better user control and generalizability. To achieve generation on continuous space, this paper employs masked autoregressive diffusion for generation.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src='images/llm_aug_survey/index_image.png' width="160">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2410.12896">
          <span class="papertitle">A Survey on Data Synthesis and Augmentation for Large Language Models</span>
        </a>
        <br>
        Ke Wang,
        Jiahui Zhu,
        Minjie Ren,
        Zeming Liu,
        <a href="https://scholar.google.com/citations?user=MHVVwYUAAAAJ">Shiwei Li</a>,
        <a href="https://zzysteve.github.io/">Zongye Zhang</a>,
        Chenkai Zhang,
        Xiaoyu Wu,
        Qiqi Zhan,
        <a href="https://scholar.google.com/citations?user=HsLdRZYAAAAJ">Qingjie Liu</a>,
        <a href="https://scholar.google.com/citations?user=0ez7lA0AAAAJ">Yunhong Wang</a>
        <br>
        <em>ArXiv</em>, 2024
        <br>
        <!-- <a href="https://szymanowiczs.github.io/bolt3d">project page</a> -->
        <a href="https://arxiv.org/pdf/2410.12896">paper</a>
        <p></p>
        This paper reviews and summarizes data generation techniques throughout the lifecycle of LLMs, including data preparation, pre-training, fine-tuning, instruction-tuning, preference alignment, and applications.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src='images/skeletonx/index_image.png' width="160">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2504.11749">
          <span class="papertitle">SkeletonX: Data-Efficient Skeleton-based Action Recognition via Cross-sample Feature Aggregation</span>
        </a>
        <br>
        <a href="https://zzysteve.github.io/">Zongye Zhang</a>,
        <a href="https://scholar.google.com/citations?user=MnalPfkAAAAJ">Wenrui Cai</a>,
        <a href="https://scholar.google.com/citations?user=HsLdRZYAAAAJ">Qingjie Liu</a>,
        <a href="https://scholar.google.com/citations?user=0ez7lA0AAAAJ">Yunhong Wang</a>
        <br>
        <em>IEEE Transaction on Multimedia (TMM)</em>, 2025
        <br>
        <!-- <a href="https://szymanowiczs.github.io/bolt3d">project page</a> -->
        <a href="https://arxiv.org/pdf/2504.11749">arXiv</a>
        /
        <a href="https://github.com/zzysteve/SkeletonX">code</a>
        <p></p>
        <p>
        
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src='images/skeleton_mix/index_image.png' width="160">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/10888125">
          <span class="papertitle">SkeletonMix: A Mixup-Based Data Augmentation Framework for Skeleton-Based Action Recognition</span>
        </a>
        <br>
        <a href="https://zzysteve.github.io/">Zongye Zhang</a>,
        <a href="https://github.com/zhysora/">Huanyu Zhou</a>,
        <a href="https://scholar.google.com/citations?user=HsLdRZYAAAAJ">Qingjie Liu</a>,
        <a href="https://scholar.google.com/citations?user=0ez7lA0AAAAJ">Yunhong Wang</a>
        <br>
        <em>IEEE ICASSP</em>, 2025
        <br>
        <!-- <a href="https://szymanowiczs.github.io/bolt3d">project page</a> -->
        <a href="https://ieeexplore.ieee.org/abstract/document/10888125">paper</a>
        <p></p>
        <p>
        By selecting samples for mixup, the proposed method reduces the number of samples needed for training for existing GCN-based skeleton action recognition models.
        </p>
      </td>
    </tr>

    </tbody></table>



    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <h2>Academic Service</h2>
      <p></p>
      <li>Reviewer: IEEE Transaction on Circuits and Systems for Video Technology</li>

    </tbody></table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:middle;font-size:small;">
                  This website use source code from <a href="https://github.com/jonbarron/jonbarron_website"> this repo</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
    
    <div style="text-align:center; margin-top:20px; margin-bottom:20px;">
      <script type="text/javascript" id="clustrmaps" 
        src="https://clustrmaps.com/map_v2.js?d=Q37faR6LjCBHH3hy4WlQ34s8K5xOe_1v2eXyzTvJMQY&cl=ffffff&w=200&h=100">
      </script>
    </div>
    
  </body>
</html>
